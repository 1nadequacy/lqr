{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from video import VideoRecorder\n",
    "import dmc2gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = dmc2gym.make('point_mass', 'easy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReplayBuffer(object):\n",
    "    def __init__(self, obs_dim, action_dim, device, capacity):\n",
    "        self.device = device\n",
    "        self.capacity = capacity\n",
    "\n",
    "        self.obses = np.empty((capacity, obs_dim), dtype=np.float32)\n",
    "        self.next_obses = np.empty((capacity, obs_dim), dtype=np.float32)\n",
    "        self.actions = np.empty((capacity, action_dim), dtype=np.float32)\n",
    "        self.rewards = np.empty((capacity, 1), dtype=np.float32)\n",
    "        self.not_dones = np.empty((capacity, 1), dtype=np.float32)\n",
    "\n",
    "        self.idx = 0\n",
    "        self.full = False\n",
    "\n",
    "    def add(self, obs, action, reward, next_obs, done):\n",
    "        np.copyto(self.obses[self.idx], obs)\n",
    "        np.copyto(self.actions[self.idx], action)\n",
    "        np.copyto(self.rewards[self.idx], reward)\n",
    "        np.copyto(self.next_obses[self.idx], next_obs)\n",
    "        np.copyto(self.not_dones[self.idx], not done)\n",
    "\n",
    "        self.idx = (self.idx + 1) % self.capacity\n",
    "        self.full = self.full or self.idx == 0\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        idxs = np.random.randint(\n",
    "            0, self.capacity if self.full else self.idx, size=batch_size)\n",
    "\n",
    "        obses = torch.as_tensor(self.obses[idxs], device=self.device).float()\n",
    "        actions = torch.as_tensor(self.actions[idxs], device=self.device)\n",
    "        rewards = torch.as_tensor(self.rewards[idxs], device=self.device)\n",
    "        next_obses = torch.as_tensor(\n",
    "            self.next_obses[idxs], device=self.device).float()\n",
    "        not_dones = torch.as_tensor(self.not_dones[idxs], device=self.device)\n",
    "\n",
    "        return obses, actions, rewards, next_obses, not_dones\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransitionModel(nn.Module):\n",
    "    def __init__(self, state_dim, control_dim):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.F = nn.Parameter(torch.rand(state_dim, state_dim + control_dim))\n",
    "        self.f = nn.Parameter(torch.zeros(state_dim))\n",
    "        \n",
    "    def forward(self, x, u):\n",
    "        # f(x, u) = F * [x u]^T + f\n",
    "        xu = torch.cat([x, u], dim=-1)\n",
    "        return xu.matmul(self.F.t()) + self.f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CostModel(nn.Module):\n",
    "    def __init__(self, state_dim, control_dim):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.C = nn.Parameter(torch.eye(state_dim + control_dim))\n",
    "        self.C.data[4, 4] = 0.0001\n",
    "        self.C.data[5, 5] = 0.0001\n",
    "        self.c = nn.Parameter(torch.zeros(state_dim + control_dim))\n",
    "        \n",
    "    def forward(self, x, u):\n",
    "        # c(x, u) = 0.5 * [x u] * C * [x u]^T + [x u] * c\n",
    "        xu = torch.cat([x, u], dim=-1)\n",
    "        return 0.5 * ((xu @ self.C.t()) * xu).sum(dim=1) + xu.matmul(self.c.t())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LQR(object):\n",
    "    def __init__(self, state_dim, control_dim):\n",
    "        self.state_dim = state_dim\n",
    "        self.control_dim = control_dim\n",
    "        \n",
    "    def _backward_pass(self, F, f, C, c, T):\n",
    "        V = torch.zeros(self.state_dim, self.state_dim)\n",
    "        v = torch.zeros(self.state_dim)\n",
    "        Ks, ks = [], []\n",
    "        N = self.state_dim\n",
    "        \n",
    "        for t in range(T - 1, 0, -1):\n",
    "            Q = C + F.t() @ V @ F\n",
    "            q = c + F.t() @ V @ f + F.t() @ v\n",
    "\n",
    "            Qxx, Qxu, Qux, Quu = Q[:N, :N], Q[:N, N:], Q[N:, :N], Q[N:, N:]\n",
    "            qx, qu = q[:N], q[N:]\n",
    "\n",
    "            Quu_inv = torch.inverse(Quu) \n",
    "            K = - Quu_inv @ Qux\n",
    "            k = - Quu_inv @ qu\n",
    "\n",
    "            Ks.append(K)\n",
    "            ks.append(k)\n",
    "\n",
    "            V = Qxx + Qxu @ K + K.t() @ Qux + K.t() @ Quu @ K\n",
    "            v = qx + Qxu @ k + K.t() @ qu + K.t() @ Quu @ k\n",
    "        \n",
    "        return reversed(Ks), reversed(ks)\n",
    "    \n",
    "    def _forward_pass(self, x, Ks, ks, trans_model):\n",
    "        us = []\n",
    "        for K, k in zip(Ks, ks):\n",
    "            u = K @ x + k\n",
    "            u = u.clamp(-1, 1)\n",
    "            us.append(u)\n",
    "            x = trans_model(x, u)\n",
    "        return us\n",
    "        \n",
    "        \n",
    "    def plan(self, x, T, trans_model, cost_model):\n",
    "        F, f = trans_model.F.detach(), trans_model.f.detach()\n",
    "        C, c = cost_model.C.detach(), cost_model.c.detach()\n",
    "        \n",
    "        Ks, ks = self._backward_pass(F, f, C, c, T)\n",
    "        us = self._forward_pass(x, Ks, ks, trans_model)\n",
    "        \n",
    "        return us"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dim = env.observation_space.shape[0]\n",
    "control_dim = env.action_space.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_model = TransitionModel(state_dim, control_dim)\n",
    "cost_model = CostModel(state_dim, control_dim)\n",
    "lqr = LQR(state_dim, control_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "buffer = ReplayBuffer(state_dim, control_dim, device, 100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(100):\n",
    "    x = env.reset()\n",
    "    u = env.action_space.sample()\n",
    "    next_x, reward, done, _ = env.step(u)\n",
    "    buffer.add(x, u, reward, next_x, float(done))\n",
    "    x = next_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_opt = torch.optim.Adam(trans_model.parameters())\n",
    "cost_opt = torch.optim.Adam(cost_model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 0 step: 998 reward: 0.000 trans loss: 0.006 cost loss: 0.000\n",
      "episode: 1 step: 998 reward: 668.616 trans loss: 0.000 cost loss: 0.000\n"
     ]
    }
   ],
   "source": [
    "for it in range(100):\n",
    "    \n",
    "    total_trans_loss = 0\n",
    "    total_cost_loss = 0\n",
    "    U = 10000\n",
    "    for _ in range(U):\n",
    "        x, u, r, nx, _ = buffer.sample(64)\n",
    "    \n",
    "        trans_opt.zero_grad()\n",
    "        trans_loss = F.mse_loss(trans_model(x, u), nx)\n",
    "        trans_loss.backward()\n",
    "        trans_opt.step()\n",
    "\n",
    "        #cost_opt.zero_grad()\n",
    "        #cost_loss = F.mse_loss(cost_model(x, u), 1. - r)\n",
    "        #cost_loss.backward()\n",
    "        #cost_opt.step()\n",
    "        \n",
    "        total_trans_loss += trans_loss.item()\n",
    "        #total_cost_loss += cost_loss.item()\n",
    "        \n",
    "    total_cost_loss /= U\n",
    "    total_trans_loss /= U\n",
    "        \n",
    "    \n",
    "    video = VideoRecorder(env, enabled=True)\n",
    "    x = env.reset()\n",
    "    us = lqr.plan(torch.as_tensor(x).float(), 1000, trans_model, cost_model)\n",
    "    \n",
    "    total_reward = 0\n",
    "    for j, u in enumerate(us):\n",
    "        \n",
    "        u = u.detach().numpy().clip(-0.999, 0.999)\n",
    "        if np.isnan(u[0]):\n",
    "            break\n",
    "        next_x, reward, done, _ = env.step(u)\n",
    "        video.record()\n",
    "        total_reward += reward\n",
    "        \n",
    "        buffer.add(x, u, reward, next_x, float(done))\n",
    "        x = next_x\n",
    "        \n",
    "    video.save('video', '%d.mp4' % it)\n",
    "    \n",
    "    \n",
    "    print('episode: %d step: %d reward: %.3f trans loss: %.3f cost loss: %.3f' % (it, j, total_reward, total_trans_loss, total_cost_loss))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.7701,  0.0489,  0.1073,  0.1030, -0.0519,  0.1217],\n",
       "        [ 0.1691,  0.4826,  0.1812, -0.5827, -0.0950,  0.3328],\n",
       "        [-0.0354, -0.0146,  0.5991,  0.1599,  0.0305, -0.0157],\n",
       "        [ 0.1713, -0.1617,  0.7018, -0.3640,  0.2524, -0.2258]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trans_model.F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "size mismatch, m1: [1 x 6], m2: [4 x 6] at /pytorch/aten/src/TH/generic/THTensorMath.cpp:961",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-5c7fb2b8405c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mu\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtran\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m: size mismatch, m1: [1 x 6], m2: [4 x 6] at /pytorch/aten/src/TH/generic/THTensorMath.cpp:961"
     ]
    }
   ],
   "source": [
    "torch.mm(torch.cat([x, u], dim=-1), tran.F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'xu' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-0ad11d65b0eb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mxu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'xu' is not defined"
     ]
    }
   ],
   "source": [
    "xu.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = CostModel(4, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c(x, u).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xu.matmul(c.c.t()).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
